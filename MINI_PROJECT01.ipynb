{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNICtpUDffnIdqVj0lNAa9L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yesserch-web/habit-tracker/blob/main/MINI_PROJECT01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2Q1y7hfvrep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Vérifiez les fichiers importés dans le répertoire de travail\n",
        "print(\"Contenu du répertoire actuel :\")\n",
        "print(os.listdir('/content'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY1ZiK7AwtuZ",
        "outputId": "fa78c1f8-82d0-4c84-b7ba-c7f9cc05166e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenu du répertoire actuel :\n",
            "['.config', 'Covid_dataset', 'Covid_dataset.zip', '.ipynb_checkpoints', 'Evaluation Set.zip', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Covid_dataset.zip'  # Remplacez par le nom de votre fichier\n",
        "extract_to = '/content/Covid_dataset'   # Répertoire cible\n",
        "\n",
        "# Décompression\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Le fichier a été décompressé dans : {extract_to}\")\n",
        "print(\"Contenu :\", os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "_XbtsJVUw16F",
        "outputId": "6c78ec33-517b-4148-c4e9-88150330979c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e758ca5c9be3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Décompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mimetypes\n",
        "\n",
        "# Vérifiez le type MIME du fichier\n",
        "mime_type, _ = mimetypes.guess_type(zip_path)\n",
        "print(f\"Le type MIME du fichier est : {mime_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrRqGvJ0xSFH",
        "outputId": "b401ba5f-2946-43e6-d664-35f136b25109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le type MIME du fichier est : application/zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcav3D8FycMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Covid_dataset (3).zip'  # Remplacez par le nom de votre fichier\n",
        "extract_to = '/content/Covid_dataset (3)'     # Répertoire cible\n",
        "\n",
        "# Décompression\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Le fichier a été décompressé dans : {extract_to}\")\n",
        "print(\"Contenu :\", os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5C5wK7GykYN",
        "outputId": "6c05dcc5-3876-43bc-9a08-856219a2ab55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier a été décompressé dans : /content/Covid_dataset (3)\n",
            "Contenu : ['train', '__MACOSX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_dir = '/content/Covid_dataset (3)/train'\n",
        "print(\"Contenu de 'train' :\", os.listdir(train_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9AfhQYfzYmt",
        "outputId": "73e1c417-631f-49fc-ebc4-3670d42fcb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenu de 'train' : ['CovidNegative', 'CovidPositive', 'ZKEZEFXA', '.DS_Store']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Chemin vers le fichier zip\n",
        "zip_path = '/content/Evaluation Set (1).zip'\n",
        "extract_to = '/content/Evaluation_Set'  # Dossier où vous souhaitez extraire le contenu\n",
        "\n",
        "# Décompression\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# Vérification du contenu\n",
        "print(\"Contenu du dossier extrait : \", os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzjQeWis0TQR",
        "outputId": "69550b70-6d3e-46e0-cf7b-7b308a13df45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenu du dossier extrait :  ['__MACOSX', 'Evaluation Set']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "# Décompression du fichier d'évaluation\n",
        "zip_path = '/content/Evaluation Set (1).zip'\n",
        "extract_to = '/content/Evaluation_Set'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# Vérification du contenu\n",
        "print(\"Contenu du dossier extrait : \", os.listdir(extract_to))\n",
        "\n",
        "# Configuration\n",
        "train_dir = '//content/sample_data/Covid_dataset (3).zip'  # Nouveau chemin pour les données d'entraînement\n",
        "eval_dir ='/content/sample_data/Evaluation Set (1).zip'  # Nouveau chemin pour le dossier d'évaluation\n",
        "output_file = \"result.txt\"\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "image_size = 224\n",
        "\n",
        "# Dataset Class\n",
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.labels = {\"CovidPositive\": 1, \"CovidNegative\": 0}\n",
        "\n",
        "        # Vérification du contenu des sous-dossiers\n",
        "        print(f\"Vérification des sous-dossiers dans {root_dir}:\")\n",
        "        for label in self.labels:\n",
        "            folder_path = os.path.join(root_dir, label)\n",
        "            if os.path.isdir(folder_path):\n",
        "                print(f\"Le dossier {label} existe.\")\n",
        "                for img_name in os.listdir(folder_path):\n",
        "                    img_path = os.path.join(folder_path, img_name)\n",
        "                    self.samples.append((img_path, self.labels[label]))\n",
        "            else:\n",
        "                print(f\"Le dossier {label} n'existe pas !\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets et DataLoaders\n",
        "train_dataset = ChestXrayDataset(train_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Modèle (ResNet18 pré-entraîné)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # Classification binaire\n",
        "\n",
        "# Loss et Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Boucle d'entraînement\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Évaluation\n",
        "model.eval()\n",
        "eval_images = sorted(os.listdir(eval_dir))\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_name in eval_images:\n",
        "        img_path = os.path.join(eval_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        results.append((img_name, predicted.item()))\n",
        "\n",
        "# Sauvegarder les résultats\n",
        "with open(output_file, \"w\") as f:\n",
        "    for img_name, label in results:\n",
        "        f.write(f\"{img_name} {label}\\n\")\n",
        "\n",
        "print(f\"Results saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "HJQegJ6D0d0o",
        "outputId": "cca9a466-6db0-4953-bd69-659ad6897789"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Evaluation Set (1).zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8acb50340fb9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mextract_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Evaluation_Set'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Evaluation Set (1).zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    if not os.path.exists(zip_path):\n",
        "        raise FileNotFoundError(f\"Le fichier ZIP '{zip_path}' n'existe pas. Vérifiez le chemin.\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"✅ Extraction terminée : {extract_to}\")\n",
        "\n",
        "\n",
        "train_zip_path = '/content/sample_data/Covid_dataset (3).zip'\n",
        "eval_zip_path = '/content/sample_data/Evaluation Set (1).zip'\n",
        "\n",
        "\n",
        "train_extract_to = '/content/Covid_dataset'\n",
        "eval_extract_to = '/content/Evaluation_Set'\n",
        "\n",
        "\n",
        "extract_zip(train_zip_path, train_extract_to)\n",
        "extract_zip(eval_zip_path, eval_extract_to)\n",
        "\n",
        "\n",
        "train_dir = '/content/Covid_dataset/train'\n",
        "eval_dir = '/content/Evaluation_Set/Evaluation Set'\n",
        "output_file = \"result.txt\"\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "image_size = 224\n",
        "\n",
        "\n",
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.labels = {\"CovidPositive\": 1, \"CovidNegative\": 0}\n",
        "\n",
        "        for label in self.labels:\n",
        "            folder_path = os.path.join(root_dir, label)\n",
        "            if not os.path.exists(folder_path):\n",
        "                raise FileNotFoundError(f\"Le dossier '{folder_path}' n'existe pas !\")\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                self.samples.append((img_path, self.labels[label]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = ChestXrayDataset(train_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "eval_images = sorted(os.listdir(eval_dir))\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_name in eval_images:\n",
        "        img_path = os.path.join(eval_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        results.append((img_name, predicted.item()))\n",
        "\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    for img_name, label in results:\n",
        "        f.write(f\"{img_name} {label}\\n\")\n",
        "\n",
        "print(f\"✅ Résultats enregistrés dans le fichier : {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuPsfRG6Hu-5",
        "outputId": "a1f819a1-8171-44bc-fd41-272cfbf6c1ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction terminée : /content/Covid_dataset\n",
            "✅ Extraction terminée : /content/Evaluation_Set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 80.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2542\n",
            "Epoch [2/10], Loss: 0.1246\n",
            "Epoch [3/10], Loss: 0.0253\n",
            "Epoch [4/10], Loss: 0.0208\n",
            "Epoch [5/10], Loss: 0.0458\n",
            "Epoch [6/10], Loss: 0.0104\n",
            "Epoch [7/10], Loss: 0.0026\n",
            "Epoch [8/10], Loss: 0.0028\n",
            "Epoch [9/10], Loss: 0.0006\n",
            "Epoch [10/10], Loss: 0.0012\n",
            "✅ Résultats enregistrés dans le fichier : result.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define the file paths\n",
        "zip_path = '/content/Evaluation Set (1).zip'\n",
        "extract_to = '/content/Evaluation_Set'\n",
        "\n",
        "# Check if the ZIP file exists\n",
        "if not os.path.exists(zip_path):\n",
        "    print(f\"❌ Le fichier ZIP '{zip_path}' n'existe pas dans l'environnement Colab.\")\n",
        "    print(\"💡 Assurez-vous d'avoir importé le fichier correctement.\")\n",
        "    print(\"💡 Utilisez le bouton '📤 Importer' dans Colab ou vérifiez le chemin.\")\n",
        "    print(\"📂 Contenu actuel de '/content':\", os.listdir('/content'))\n",
        "else:\n",
        "    print(f\"✅ Le fichier ZIP '{zip_path}' a été trouvé.\")\n",
        "    print(\"🔄 Décompression en cours...\")\n",
        "\n",
        "    # Extract the ZIP file\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"✅ Décompression terminée. Les fichiers sont extraits dans '{extract_to}'.\")\n",
        "        print(\"📂 Contenu de l'extraction :\", os.listdir(extract_to))\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\"❌ Erreur : Le fichier n'est pas un fichier ZIP valide.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZKCSRS5GqQm",
        "outputId": "66340816-43ea-4724-e6d7-516abe87ff50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Le fichier ZIP '/content/Evaluation Set (1).zip' n'existe pas dans l'environnement Colab.\n",
            "💡 Assurez-vous d'avoir importé le fichier correctement.\n",
            "💡 Utilisez le bouton '📤 Importer' dans Colab ou vérifiez le chemin.\n",
            "📂 Contenu actuel de '/content': ['.config', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemin du dossier d'évaluation\n",
        "eval_dir = '/content/Evaluation_Set/Evaluation Set'  # Remplacez par le chemin correct\n",
        "\n",
        "# Compter le nombre de fichiers image\n",
        "if os.path.exists(eval_dir):\n",
        "    eval_files = [f for f in os.listdir(eval_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"Nombre total d'images dans le dossier d'évaluation : {len(eval_files)}\")\n",
        "else:\n",
        "    print(f\"Le dossier '{eval_dir}' n'existe pas !\")\n"
      ],
      "metadata": {
        "id": "DhN-LIbk4qhH",
        "outputId": "1b187a5b-05da-490d-debb-d601af7fd93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le dossier '/content/Evaluation_Set/Evaluation Set' n'existe pas !\n"
          ]
        }
      ]
    }
  ]
}