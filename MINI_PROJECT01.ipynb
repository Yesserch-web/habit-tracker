{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNICtpUDffnIdqVj0lNAa9L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yesserch-web/habit-tracker/blob/main/MINI_PROJECT01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2Q1y7hfvrep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# V√©rifiez les fichiers import√©s dans le r√©pertoire de travail\n",
        "print(\"Contenu du r√©pertoire actuel :\")\n",
        "print(os.listdir('/content'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY1ZiK7AwtuZ",
        "outputId": "fa78c1f8-82d0-4c84-b7ba-c7f9cc05166e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenu du r√©pertoire actuel :\n",
            "['.config', 'Covid_dataset', 'Covid_dataset.zip', '.ipynb_checkpoints', 'Evaluation Set.zip', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Covid_dataset.zip'  # Remplacez par le nom de votre fichier\n",
        "extract_to = '/content/Covid_dataset'   # R√©pertoire cible\n",
        "\n",
        "# D√©compression\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Le fichier a √©t√© d√©compress√© dans : {extract_to}\")\n",
        "print(\"Contenu :\", os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "_XbtsJVUw16F",
        "outputId": "6c78ec33-517b-4148-c4e9-88150330979c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e758ca5c9be3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# D√©compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mimetypes\n",
        "\n",
        "# V√©rifiez le type MIME du fichier\n",
        "mime_type, _ = mimetypes.guess_type(zip_path)\n",
        "print(f\"Le type MIME du fichier est : {mime_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrRqGvJ0xSFH",
        "outputId": "b401ba5f-2946-43e6-d664-35f136b25109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le type MIME du fichier est : application/zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcav3D8FycMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Covid_dataset (3).zip'  # Remplacez par le nom de votre fichier\n",
        "extract_to = '/content/Covid_dataset (3)'     # R√©pertoire cible\n",
        "\n",
        "# D√©compression\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Le fichier a √©t√© d√©compress√© dans : {extract_to}\")\n",
        "print(\"Contenu :\", os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5C5wK7GykYN",
        "outputId": "6c05dcc5-3876-43bc-9a08-856219a2ab55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier a √©t√© d√©compress√© dans : /content/Covid_dataset (3)\n",
            "Contenu : ['train', '__MACOSX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_dir = '/content/Covid_dataset (3)/train'\n",
        "print(\"Contenu de 'train' :\", os.listdir(train_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9AfhQYfzYmt",
        "outputId": "73e1c417-631f-49fc-ebc4-3670d42fcb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenu de 'train' : ['CovidNegative', 'CovidPositive', 'ZKEZEFXA', '.DS_Store']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Chemin vers le fichier zip\n",
        "zip_path = '/content/Evaluation Set (1).zip'\n",
        "extract_to = '/content/Evaluation_Set'  # Dossier o√π vous souhaitez extraire le contenu\n",
        "\n",
        "# D√©compression\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# V√©rification du contenu\n",
        "print(\"Contenu du dossier extrait : \", os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzjQeWis0TQR",
        "outputId": "69550b70-6d3e-46e0-cf7b-7b308a13df45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenu du dossier extrait :  ['__MACOSX', 'Evaluation Set']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "# D√©compression du fichier d'√©valuation\n",
        "zip_path = '/content/Evaluation Set (1).zip'\n",
        "extract_to = '/content/Evaluation_Set'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# V√©rification du contenu\n",
        "print(\"Contenu du dossier extrait : \", os.listdir(extract_to))\n",
        "\n",
        "# Configuration\n",
        "train_dir = '//content/sample_data/Covid_dataset (3).zip'  # Nouveau chemin pour les donn√©es d'entra√Ænement\n",
        "eval_dir ='/content/sample_data/Evaluation Set (1).zip'  # Nouveau chemin pour le dossier d'√©valuation\n",
        "output_file = \"result.txt\"\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "image_size = 224\n",
        "\n",
        "# Dataset Class\n",
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.labels = {\"CovidPositive\": 1, \"CovidNegative\": 0}\n",
        "\n",
        "        # V√©rification du contenu des sous-dossiers\n",
        "        print(f\"V√©rification des sous-dossiers dans {root_dir}:\")\n",
        "        for label in self.labels:\n",
        "            folder_path = os.path.join(root_dir, label)\n",
        "            if os.path.isdir(folder_path):\n",
        "                print(f\"Le dossier {label} existe.\")\n",
        "                for img_name in os.listdir(folder_path):\n",
        "                    img_path = os.path.join(folder_path, img_name)\n",
        "                    self.samples.append((img_path, self.labels[label]))\n",
        "            else:\n",
        "                print(f\"Le dossier {label} n'existe pas !\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets et DataLoaders\n",
        "train_dataset = ChestXrayDataset(train_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Mod√®le (ResNet18 pr√©-entra√Æn√©)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # Classification binaire\n",
        "\n",
        "# Loss et Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Boucle d'entra√Ænement\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# √âvaluation\n",
        "model.eval()\n",
        "eval_images = sorted(os.listdir(eval_dir))\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_name in eval_images:\n",
        "        img_path = os.path.join(eval_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        results.append((img_name, predicted.item()))\n",
        "\n",
        "# Sauvegarder les r√©sultats\n",
        "with open(output_file, \"w\") as f:\n",
        "    for img_name, label in results:\n",
        "        f.write(f\"{img_name} {label}\\n\")\n",
        "\n",
        "print(f\"Results saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "HJQegJ6D0d0o",
        "outputId": "cca9a466-6db0-4953-bd69-659ad6897789"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Evaluation Set (1).zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8acb50340fb9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mextract_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/Evaluation_Set'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Evaluation Set (1).zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    if not os.path.exists(zip_path):\n",
        "        raise FileNotFoundError(f\"Le fichier ZIP '{zip_path}' n'existe pas. V√©rifiez le chemin.\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"‚úÖ Extraction termin√©e : {extract_to}\")\n",
        "\n",
        "\n",
        "train_zip_path = '/content/sample_data/Covid_dataset (3).zip'\n",
        "eval_zip_path = '/content/sample_data/Evaluation Set (1).zip'\n",
        "\n",
        "\n",
        "train_extract_to = '/content/Covid_dataset'\n",
        "eval_extract_to = '/content/Evaluation_Set'\n",
        "\n",
        "\n",
        "extract_zip(train_zip_path, train_extract_to)\n",
        "extract_zip(eval_zip_path, eval_extract_to)\n",
        "\n",
        "\n",
        "train_dir = '/content/Covid_dataset/train'\n",
        "eval_dir = '/content/Evaluation_Set/Evaluation Set'\n",
        "output_file = \"result.txt\"\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "image_size = 224\n",
        "\n",
        "\n",
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        self.labels = {\"CovidPositive\": 1, \"CovidNegative\": 0}\n",
        "\n",
        "        for label in self.labels:\n",
        "            folder_path = os.path.join(root_dir, label)\n",
        "            if not os.path.exists(folder_path):\n",
        "                raise FileNotFoundError(f\"Le dossier '{folder_path}' n'existe pas !\")\n",
        "            for img_name in os.listdir(folder_path):\n",
        "                img_path = os.path.join(folder_path, img_name)\n",
        "                self.samples.append((img_path, self.labels[label]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = ChestXrayDataset(train_dir, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "eval_images = sorted(os.listdir(eval_dir))\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_name in eval_images:\n",
        "        img_path = os.path.join(eval_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        results.append((img_name, predicted.item()))\n",
        "\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    for img_name, label in results:\n",
        "        f.write(f\"{img_name} {label}\\n\")\n",
        "\n",
        "print(f\"‚úÖ R√©sultats enregistr√©s dans le fichier : {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuPsfRG6Hu-5",
        "outputId": "a1f819a1-8171-44bc-fd41-272cfbf6c1ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extraction termin√©e : /content/Covid_dataset\n",
            "‚úÖ Extraction termin√©e : /content/Evaluation_Set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 80.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2542\n",
            "Epoch [2/10], Loss: 0.1246\n",
            "Epoch [3/10], Loss: 0.0253\n",
            "Epoch [4/10], Loss: 0.0208\n",
            "Epoch [5/10], Loss: 0.0458\n",
            "Epoch [6/10], Loss: 0.0104\n",
            "Epoch [7/10], Loss: 0.0026\n",
            "Epoch [8/10], Loss: 0.0028\n",
            "Epoch [9/10], Loss: 0.0006\n",
            "Epoch [10/10], Loss: 0.0012\n",
            "‚úÖ R√©sultats enregistr√©s dans le fichier : result.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define the file paths\n",
        "zip_path = '/content/Evaluation Set (1).zip'\n",
        "extract_to = '/content/Evaluation_Set'\n",
        "\n",
        "# Check if the ZIP file exists\n",
        "if not os.path.exists(zip_path):\n",
        "    print(f\"‚ùå Le fichier ZIP '{zip_path}' n'existe pas dans l'environnement Colab.\")\n",
        "    print(\"üí° Assurez-vous d'avoir import√© le fichier correctement.\")\n",
        "    print(\"üí° Utilisez le bouton 'üì§ Importer' dans Colab ou v√©rifiez le chemin.\")\n",
        "    print(\"üìÇ Contenu actuel de '/content':\", os.listdir('/content'))\n",
        "else:\n",
        "    print(f\"‚úÖ Le fichier ZIP '{zip_path}' a √©t√© trouv√©.\")\n",
        "    print(\"üîÑ D√©compression en cours...\")\n",
        "\n",
        "    # Extract the ZIP file\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"‚úÖ D√©compression termin√©e. Les fichiers sont extraits dans '{extract_to}'.\")\n",
        "        print(\"üìÇ Contenu de l'extraction :\", os.listdir(extract_to))\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\"‚ùå Erreur : Le fichier n'est pas un fichier ZIP valide.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZKCSRS5GqQm",
        "outputId": "66340816-43ea-4724-e6d7-516abe87ff50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Le fichier ZIP '/content/Evaluation Set (1).zip' n'existe pas dans l'environnement Colab.\n",
            "üí° Assurez-vous d'avoir import√© le fichier correctement.\n",
            "üí° Utilisez le bouton 'üì§ Importer' dans Colab ou v√©rifiez le chemin.\n",
            "üìÇ Contenu actuel de '/content': ['.config', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemin du dossier d'√©valuation\n",
        "eval_dir = '/content/Evaluation_Set/Evaluation Set'  # Remplacez par le chemin correct\n",
        "\n",
        "# Compter le nombre de fichiers image\n",
        "if os.path.exists(eval_dir):\n",
        "    eval_files = [f for f in os.listdir(eval_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"Nombre total d'images dans le dossier d'√©valuation : {len(eval_files)}\")\n",
        "else:\n",
        "    print(f\"Le dossier '{eval_dir}' n'existe pas !\")\n"
      ],
      "metadata": {
        "id": "DhN-LIbk4qhH",
        "outputId": "1b187a5b-05da-490d-debb-d601af7fd93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le dossier '/content/Evaluation_Set/Evaluation Set' n'existe pas !\n"
          ]
        }
      ]
    }
  ]
}